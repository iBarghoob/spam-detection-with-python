{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries"
      ],
      "metadata": {
        "id": "gmL6V98P6lRb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "O8CXHgNi6IXu"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import *\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.neighbors import *\n",
        "from sklearn.tree import *\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.multiclass import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test combinations of classifiers and vectorizers"
      ],
      "metadata": {
        "id": "ZzOSkNfB6qlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "testing combinations of classifiers and vectorizers\n",
        "1. tries combinatios of classifiers and vectorizers in scikit-learn lib\n",
        "2. trains classifier on vectorized training data\n",
        "3. tests on test data\n",
        "4. prints classification score\n",
        "v1 = first label 'ham' or 'spam'\n",
        "v2 = actual message\n",
        "\"\"\"\n",
        "def perform(classifiers, vectorizers, train_data, test_data):\n",
        "    for classifier in classifiers:\n",
        "        for vectorizer in vectorizers:\n",
        "            start = time.time()\n",
        "\n",
        "            # vectorize to transform text to numerical vectors\n",
        "            X_train = vectorizer.fit_transform(train_data.v2)\n",
        "\n",
        "            # fit classifier on vectorized data with labels\n",
        "            classifier.fit(X_train, train_data.v1)\n",
        "\n",
        "            # vectorize test data and show score for each classifier\n",
        "            X_test = vectorizer.transform(test_data.v2)\n",
        "            classification_score = classifier.score(X_test, test_data.v1)\n",
        "\n",
        "            end = time.time()\n",
        "            elapsed_time = end - start\n",
        "            score_string = f\"{classifier.__class__.__name__} with {vectorizer.__class__.__name__}, Score: {classification_score}, Time: {elapsed_time:.2f}s\"\n",
        "            print(score_string)\n"
      ],
      "metadata": {
        "id": "Ga6AQA7t6uJp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide data-set 80/20 train/test\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['v1'])"
      ],
      "metadata": {
        "id": "mDM-Iu3M60yJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and testing cominbations of classifiers and vectorizers for this dataset"
      ],
      "metadata": {
        "id": "ttFTYEotiK0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = [\n",
        "    BernoulliNB(),\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    PassiveAggressiveClassifier(),\n",
        "    RidgeClassifier(),\n",
        "    SGDClassifier(),\n",
        "    OneVsRestClassifier(SVC(kernel='linear', probability=True)),\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    MultinomialNB(),\n",
        "\n",
        "]\n",
        "\n",
        "vectorizers = [\n",
        "    CountVectorizer(),\n",
        "    TfidfVectorizer(),\n",
        "]\n",
        "\n",
        "perform(classifiers, vectorizers, train_data, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryRJBloI615Q",
        "outputId": "8e700866-295f-4a20-b288-5655ab0e04f3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BernoulliNB with CountVectorizer, Score: 0.9721973094170404, Time: 0.28s\n",
            "BernoulliNB with TfidfVectorizer, Score: 0.9721973094170404, Time: 0.41s\n",
            "LogisticRegression with CountVectorizer, Score: 0.9847533632286996, Time: 0.22s\n",
            "LogisticRegression with TfidfVectorizer, Score: 0.9695067264573991, Time: 0.21s\n",
            "PassiveAggressiveClassifier with CountVectorizer, Score: 0.9856502242152466, Time: 0.16s\n",
            "PassiveAggressiveClassifier with TfidfVectorizer, Score: 0.9865470852017937, Time: 0.11s\n",
            "RidgeClassifier with CountVectorizer, Score: 0.9739910313901345, Time: 0.17s\n",
            "RidgeClassifier with TfidfVectorizer, Score: 0.9874439461883409, Time: 0.14s\n",
            "SGDClassifier with CountVectorizer, Score: 0.97847533632287, Time: 0.11s\n",
            "SGDClassifier with TfidfVectorizer, Score: 0.9901345291479821, Time: 0.12s\n",
            "OneVsRestClassifier with CountVectorizer, Score: 0.9847533632286996, Time: 3.36s\n",
            "OneVsRestClassifier with TfidfVectorizer, Score: 0.9910313901345291, Time: 5.61s\n",
            "KNeighborsClassifier with CountVectorizer, Score: 0.9192825112107623, Time: 0.38s\n",
            "KNeighborsClassifier with TfidfVectorizer, Score: 0.9121076233183857, Time: 0.27s\n",
            "DecisionTreeClassifier with CountVectorizer, Score: 0.9739910313901345, Time: 0.31s\n",
            "DecisionTreeClassifier with TfidfVectorizer, Score: 0.95695067264574, Time: 0.54s\n",
            "RandomForestClassifier with CountVectorizer, Score: 0.9713004484304932, Time: 1.46s\n",
            "RandomForestClassifier with TfidfVectorizer, Score: 0.9739910313901345, Time: 1.62s\n",
            "MultinomialNB with CountVectorizer, Score: 0.9847533632286996, Time: 0.11s\n",
            "MultinomialNB with TfidfVectorizer, Score: 0.9560538116591928, Time: 0.13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### results\n",
        "\n",
        "```\n",
        "BernoulliNB with CountVectorizer, Score: 0.9721973094170404, Time: 0.28s\n",
        "BernoulliNB with TfidfVectorizer, Score: 0.9721973094170404, Time: 0.41s\n",
        "LogisticRegression with CountVectorizer, Score: 0.9847533632286996, Time: 0.22s\n",
        "LogisticRegression with TfidfVectorizer, Score: 0.9695067264573991, Time: 0.21s\n",
        "PassiveAggressiveClassifier with CountVectorizer, Score: 0.9856502242152466, Time: 0.16s\n",
        "PassiveAggressiveClassifier with TfidfVectorizer, Score: 0.9865470852017937, Time: 0.11s\n",
        "RidgeClassifier with CountVectorizer, Score: 0.9739910313901345, Time: 0.17s\n",
        "RidgeClassifier with TfidfVectorizer, Score: 0.9874439461883409, Time: 0.14s\n",
        "SGDClassifier with CountVectorizer, Score: 0.97847533632287, Time: 0.11s\n",
        "SGDClassifier with TfidfVectorizer, Score: 0.9901345291479821, Time: 0.12s\n",
        "OneVsRestClassifier with CountVectorizer, Score: 0.9847533632286996, Time: 3.36s\n",
        "OneVsRestClassifier with TfidfVectorizer, Score: 0.9910313901345291, Time: 5.61s\n",
        "KNeighborsClassifier with CountVectorizer, Score: 0.9192825112107623, Time: 0.38s\n",
        "KNeighborsClassifier with TfidfVectorizer, Score: 0.9121076233183857, Time: 0.27s\n",
        "DecisionTreeClassifier with CountVectorizer, Score: 0.9739910313901345, Time: 0.31s\n",
        "DecisionTreeClassifier with TfidfVectorizer, Score: 0.95695067264574, Time: 0.54s\n",
        "RandomForestClassifier with CountVectorizer, Score: 0.9713004484304932, Time: 1.46s\n",
        "RandomForestClassifier with TfidfVectorizer, Score: 0.9739910313901345, Time: 1.62s\n",
        "MultinomialNB with CountVectorizer, Score: 0.9847533632286996, Time: 0.11s\n",
        "MultinomialNB with TfidfVectorizer, Score: 0.9560538116591928, Time: 0.13s\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "5ahzR6CojZAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using OneVsRest classifier with tf-idf  vectorizer"
      ],
      "metadata": {
        "id": "Qz93JBkQjR8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "XmO8V_2bkLoL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['v1'])"
      ],
      "metadata": {
        "id": "NCtVeRPwLDWJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving detailed results for running model on test set in a csv file"
      ],
      "metadata": {
        "id": "HLSOA9lskj2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# transform text to numerical vectors for classifier\n",
        "X_train = vectorizer.fit_transform(train_data.v2)\n",
        "# labels\n",
        "y_train = train_data.v1\n",
        "\n",
        "# trains support vector machine on vectorized data + labels\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# transform test data\n",
        "X_test = vectorizer.transform(test_data.v2)\n",
        "# labels\n",
        "y_test = test_data.v1\n",
        "\n",
        "# score\n",
        "print(classifier.score(X_test, y_test))\n",
        "\n",
        "csv_array = []\n",
        "for index, row in test_data.iterrows():\n",
        "  answer = row[0]\n",
        "  text = row[1]\n",
        "  vectorize_text = vectorizer.transform([text])\n",
        "  predict = classifier.predict(vectorize_text)[0]\n",
        "  result = \"correct\" if predict == answer else \"incorrect\"\n",
        "  csv_array.append([index, text, answer, predict, result])\n",
        "\n",
        "correct_count = sum(1 for row in csv_array if row[4] == \"correct\")\n",
        "incorrect_count = sum(1 for row in csv_array if row[4] == \"incorrect\")\n",
        "\n",
        "print(f\"Correct predictions: {correct_count}\")\n",
        "print(f\"Incorrect predictions: {incorrect_count}\")\n",
        "\n",
        "# save test results to csv file\n",
        "with open('test_results.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=';', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  writer.writerow([\"id\", \"text\", \"answer\", \"predict\", \"result\"])\n",
        "  for row in csv_array:\n",
        "    writer.writerow(row)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C822NCuXLSZV",
        "outputId": "dbb3a937-40b8-4a3d-aa16-6a84f64a6816"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9820627802690582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-41-407113505.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  answer = row[0]\n",
            "/tmp/ipython-input-41-407113505.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  text = row[1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct predictions: 1095\n",
            "Incorrect predictions: 20\n"
          ]
        }
      ]
    }
  ]
}